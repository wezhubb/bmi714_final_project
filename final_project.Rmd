---
title: "BMI 714 Final Project"
author: "Wenzhu Ye, Lindsay Cheng"
date: "`r Sys.Date()`"
output:
  html_document: 
    toc: true
    toc_depth: 3
    toc_float: true
  pdf_document: default
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::knit_engines$set(txt = function(options) {
  code <- paste(options$code, collapse = "\n")
  knitr::engine_output(options, code, NULL)
})
```

```{r}
# If not installed, install the following packages
# install.packages(c("dplyr", "ggplot2", "lubridate", "tidyr", "ggcorrplot", "caret", "glmnet"))
# Load Library here
library(dplyr)
library(ggplot2)
library(lubridate)
library(tidyr)
library(ggcorrplot)
library(caret)
library(glmnet)
library(knitr)
```

# View Data

```{r}
nhanes <- read.csv("data/BMI714_NHANES2020_Data.csv", header = T)
nhanes_var_name <- read.csv("data/BMI714_NHANES_VariableDictionary.csv", header = T)
# Rename the columns in nhanes
colnames(nhanes) <- ifelse(colnames(nhanes) %in% nhanes_var_name$BMI_714_Variable_Name, 
                           nhanes_var_name$Variable_Name[match(colnames(nhanes),nhanes_var_name$BMI_714_Variable_Name)], 
                           colnames(nhanes))  # Keep names unchanged if not in mapping
cat("Data Dimensions:", nrow(nhanes), "rows and", ncol(nhanes), "columns\n")

```

```{r}
cat("Data Dimensions for adult:", nhanes %>% dplyr::select(RIDAGEYR) %>% filter(RIDAGEYR >= 18) %>% nrow(), "rows\n")

```


```{r}
#quick examine the data
nhanes_var_name %>% dplyr::select(Data_File_Description) %>% unique()
```

```{r}
# Calculate the percentage of missing values for each column
missing_percent <- colSums(is.na(nhanes)) / nrow(nhanes)

# Filter columns with less than 20% missingness
filtered_df <- nhanes[, missing_percent < 0.20]
dim(filtered_df)
```

```{r}
# Extract the column names from the filtered dataset
filtered_columns <- colnames(filtered_df)

# Filter var_dict for rows where col_name matches the filtered column names
filtered_var_dict <- nhanes_var_name[nhanes_var_name$Variable_Name %in% filtered_columns, ]
```


```{r}
cat("Number of rows with BMI missing:", nhanes %>% dplyr::select(BMXBMI) %>% is.na() %>% sum(), "\n")
```

# Independent variable consideration

```{r}
# type of milk
milk_type_missing <- (nhanes %>% 
  dplyr::select(DBQ223A, DBQ223B, DBQ223C, DBQ223D, DBQ223E, DBQ223U) %>% 
  filter(rowSums(is.na(.)) == ncol(.)) %>%  # Check if all selected columns are NA
  nrow()) / nrow(nhanes) # Count the number of such rows
cat("Milk type missingness:", milk_type_missing, "\n")
```


```{r}
# Caffeine
# check which variable has caffeine in description
caffeine_rows <- nhanes_var_name[grep("caffeine", nhanes_var_name$Variable_Description, ignore.case = TRUE), ]

DS1TCAFF_missing <- (nhanes %>% 
  dplyr::select(DS1TCAFF) %>% 
  filter(rowSums(is.na(.)) == ncol(.)) %>%  # Check if all selected columns are NA
  nrow()) / nrow(nhanes) 
DS2TCAFF_missing <- (nhanes %>% 
  dplyr::select(DS2TCAFF) %>% 
  filter(rowSums(is.na(.)) == ncol(.)) %>%  # Check if all selected columns are NA
  nrow()) / nrow(nhanes) 

cat("DS1TCAFF missingness:", DS1TCAFF_missing, "\n")
cat("DS2TCAFF missingness:", DS2TCAFF_missing, "\n")
```


# Variable Choosen:

Dependent variable: weight(BMXWT)

Independent variable: Dairy product used(DBQ197) Type of Milk(DBQ223A,
DBQ223B, DBQ223C, DBQ223D, DBQ223E, DBQ223U) Frozen meals/ready to go
meal/fast food/resturation (DBD905, DBD910) Income(INDFMMPC)
Sleep(SLQ300, SLQ310, SLQ320, SLQ330) Smoking(SMD460) Diabetes(DIQ010)
Alcohol consumption(ALQ121)

Goal: how socioeconmic state (income), eating behaviour affect obesity
(BMI) in adult

# Prep data

```{r}
# select predictor columns
data <- nhanes %>% 
  dplyr::select(	
BMXBMI, DBQ197, DBQ223A, DBQ223B, DBQ223C, DBQ223D, DBQ223E, DBQ223U, DBD905, DBD910, INDFMMPC, SLQ300, SLQ310, SLQ320, SLQ330, SMD460, DIQ010, ALQ121, RIDAGEYR) %>% # select variables
  filter(!is.na(	
BMXBMI)) %>% # remove rows with missing BMI
filter(RIDAGEYR >= 18) # remove rows with age < 16)

```

## BMI category

according to <https://www.cdc.gov/bmi/adult-calculator/bmi-categories.html>

```{r}
# Create a new column for BMI category
data <- data %>%
  mutate(
    bmi_category = case_when(
      BMXBMI < 18.5 ~ "Underweight",
      BMXBMI >= 18.5 & BMXBMI < 25 ~ "Normal",
      BMXBMI >= 25 & BMXBMI < 30 ~ "Overweight",
      BMXBMI >= 30 ~ "Obesity",
      TRUE ~ NA_character_  # Handle missing or unexpected BMI values
    )
  )
```

## Process independent variable

Note: predictors are ordinal, encoding them to reflect their order.

```{r, warning=FALSE}
########### Type of Milk ###########
# For Type of Milk DBQ223A, DBQ223B, DBQ223C, DBQ223D, DBQ223E, DBQ223U, we will combine them into one variable. 
#  want to see combined effect of drinking mupltiple type of milk: Group participants who drink multiple types of milk into a single “Mixed Milk” category.
data <- data %>%
  rowwise() %>%
  mutate(milk_type = if_else(sum(!is.na(c(DBQ223A, DBQ223B, DBQ223C, DBQ223D, DBQ223E, DBQ223U))) > 1, 
                             "Mixed Milk", 
                             as.character(coalesce(DBQ223A, DBQ223B, DBQ223C, DBQ223D, DBQ223E, DBQ223U)))) %>%
  ungroup()

# rename milk_type
data <- data %>% mutate(milk_type = case_when(
  milk_type == "10" ~ '4', #Whole
  milk_type == "11" ~ '3', #2%
  milk_type == "12" ~ '1', # 1% or 0.5%
  milk_type == "13" ~ '0', #Skim
  milk_type == "14" ~ '2', #Soy, ~ 1.5%-2% 
  milk_type == "30" ~ '8', #Other
  milk_type == "Mixed Milk" ~ '9', #Mixed Milk
  milk_type == "77" ~ NA_character_, #Refused
  milk_type == "99" ~ NA_character_, #Unknown
  TRUE ~ NA_character_ # NA into Unknown
))


########### Milk consumption  ###########
data <- data %>%
  mutate(
    milk_consumption = case_when(
      DBQ197 == 0 ~ '0', #Never
      DBQ197 == 1 ~ '1', #less than once a week
      DBQ197 == 2 ~ '2', #once a week or more, but less than once a day
      DBQ197 == 3 ~ '3', # once a day or more
      DBQ197 == 4 ~ '9', #Varied
      DBQ197 == 7 ~ NA_character_, #Refused
      DBQ197 == 9 ~ NA_character_, #Unknow
      is.na(DBQ197) ~ NA_character_  # Handle missing values
    )
  ) 


########### Poverty  ###########
data <- data %>%
  mutate(
    poverty_category = case_when(
      INDFMMPC == 1 ~ '1', #Monthly poverty level index <= 1.30
      INDFMMPC == 2 ~ '2',# 1.30 < Monthly poverty level index <= 1.85
      INDFMMPC == 3 ~ '3', #> 1.85
      INDFMMPC == 7 ~ NA_character_, #Refused
      INDFMMPC == 9 ~ NA_character_, #"Don't know"
      is.na(INDFMMPC) ~ NA_character_  
    )
  )


########### Alcohol  ###########
data <- data %>%
  mutate(
    ALQ121 = if_else(RIDAGEYR < 18, 0, ALQ121),  # Assign 0 for age < 18
    alcohol_frequency = case_when(
      ALQ121 == 0 ~ '0', #"Never in the last year"
      ALQ121 == 1 ~ '10', #"Every day"
      ALQ121 == 2 ~ '9', #Nearly every day"
      ALQ121 == 3 ~ '8', #"3 to 4 times a week"
      ALQ121 == 4 ~ '7', #"2 times a week"
      ALQ121 == 5 ~ '6', #Once a week
      ALQ121 == 6 ~ '5', #2 to 3 times a month
      ALQ121 == 7 ~ '4', #Once a month
      ALQ121 == 8 ~ '3', #7 to 11 times in the last year
      ALQ121 == 9 ~ '2', #3 to 6 times in the last year
      ALQ121 == 10 ~ '1', #1 to 2 times in the last year
      ALQ121 == 77 ~ NA_character_, #"Refused"
      ALQ121 == 99 ~ NA_character_, #"Don't know"
      is.na(ALQ121) ~ NA_character_
    )
  )

########### Diabete ###########
data <- data %>%
  mutate(
    diabetes_status = case_when(
      DIQ010 == 1 ~ '1', #Yes
      DIQ010 == 2 ~ '0', #No
      DIQ010 == 3 ~ '0.5', #Borderline
      DIQ010 == 7 ~ NA_character_, # "Refused"
      DIQ010 == 9 ~ NA_character_, # "Don't know"
      is.na(DIQ010) ~ NA_character_  # Handle missing values
    ))



########### Second hand smoke ########### 
data <- data %>%
  mutate(
    household_smoking_status = case_when(
      SMD460 == 0 ~ '0', #No one in household is a smoker
      SMD460 == 1 ~ '1', #1 household member is a smoker
      SMD460 == 2 ~ '2', #2 or more household members are smokers
      SMD460 == 777 ~ NA_character_, #Refused
      SMD460 == 999 ~ NA_character_, #"Don't know"
      is.na(SMD460) ~ NA_character_  # Handle missing values
    )
  )



########### Fast food ########### 
# add the range of values together, from 0 - 90, if added value over 90, or either one is 6666, mark it as 90+, if either one is 7777 or 9999 and the other is 0 - 90 or 6666, use the other value. If both are 7777 or 9999, make as 7777 or 9999 correspsoned

data <- data %>%
  rowwise() %>%
  mutate(
    fast_food_consumption = case_when(
      # If either value is 6666 (More than 90 times), mark as "99"
      DBD905 == 6666 | DBD910 == 6666 ~ "99",
      
      # If the sum of values exceeds 90, mark as "99"
      sum(c(DBD905, DBD910), na.rm = TRUE) > 90 ~ "99",
      
      # If one value is 7777 or 9999 and the other is 0-90 or 6666, use the valid value
      DBD905 %in% c(7777, 9999) & DBD910 %in% c(0:90, 6666) ~ as.character(DBD910),
      DBD910 %in% c(7777, 9999) & DBD905 %in% c(0:90, 6666) ~ as.character(DBD905),
      
      # If both are 7777 or 9999, retain the corresponding value
      DBD905 %in% c(7777, 9999) & DBD910 %in% c(7777, 9999) ~ as.character(max(DBD905, DBD910)),
      
      # Otherwise, add the values (if both are 0-90) and return the sum
      TRUE ~ as.character(sum(c(DBD905, DBD910), na.rm = TRUE))
    )
  ) %>%
  ungroup()


########### sleep time ########### 
# Convert time to decimal hours
time_to_decimal <- function(time) {
  ifelse(
    time %in% c("77777", "99999") | is.na(time),
    NA,
    as.numeric(hms(paste0(time, ":00"))) / 3600
  )
}

data <- data %>%
  mutate(
    # Convert sleep and wake times to decimal hours
    sleep_weekdays = time_to_decimal(SLQ300),
    wake_weekdays = time_to_decimal(SLQ310),
    sleep_weekends = time_to_decimal(SLQ320),
    wake_weekends = time_to_decimal(SLQ330),
    
    # Calculate sleep hours, accounting for crossing midnight
    sleep_hours_weekdays = case_when(
      !is.na(sleep_weekdays) & !is.na(wake_weekdays) ~ 
        ifelse(wake_weekdays < sleep_weekdays, wake_weekdays + 24 - sleep_weekdays, wake_weekdays - sleep_weekdays),
      TRUE ~ NA_real_
    ),
    sleep_hours_weekends = case_when(
      !is.na(sleep_weekends) & !is.na(wake_weekends) ~ 
        ifelse(wake_weekends < sleep_weekends, wake_weekends + 24 - sleep_weekends, wake_weekends - sleep_weekends),
      TRUE ~ NA_real_
    ),
    
    # Calculate weighted sleep directly
    sleep_hours = (5 * sleep_hours_weekdays + 2 * sleep_hours_weekends) / 7
  )

```

## check age distribution

```{r}
# plot age distribution, ensure no extreme age like 500
data %>% ggplot(aes(x = RIDAGEYR)) +
  geom_histogram(binwidth = 10, fill = "blue", color = "black", alpha = 0.7) +
  labs(
    title = "Histogram of Weighted Sleep Hours",
    x = "Weighted Sleep Hours",
    y = "Frequency"
  ) +
  theme_minimal()
```


```{r}
# rename bmi and age columns
data <- data %>%
  dplyr::select(BMXBMI, bmi_category, RIDAGEYR, milk_type, milk_consumption, poverty_category, alcohol_frequency, diabetes_status, household_smoking_status, fast_food_consumption, sleep_hours) %>%
  rename(
    bmi = BMXBMI,
    age = RIDAGEYR
  )

head(data)
  
```

# Exploratory Data Analysis

```{r}
# Summary of data
summary(data)

# Check data structure
str(data)
```

## Missingness

NA Summary

```{r}
# Create a summary table of missing values
na_summary <- data.frame(
  Variable = colnames(data),
  NA_Count = colSums(is.na(data)),
  NA_Percentage = round(colSums(is.na(data)) / nrow(data) * 100, 2)
)

# Pretty table using kable
kable(na_summary, format = "markdown", col.names = c("Variable", "NA Count", "NA Percentage (%)"))
```

```{r}
# final data will remove all the NA rows
final_data <- data %>%
  filter(!is.na(milk_type), !is.na(milk_consumption), !is.na(poverty_category), !is.na(alcohol_frequency), !is.na(diabetes_status), !is.na(household_smoking_status), !is.na(fast_food_consumption), !is.na(sleep_hours))
```

```{r}
# Summary of data
summary(final_data)

# Check data structure
str(final_data)
```

## Factorize Ordinal Variables

predictors are ordinal, encoding them to reflect their order.

```{r}
# Factorize ordinal variables into numbers represent general level for future analysis
final_data <- final_data %>%
  mutate(bmi_category = factor(bmi_category, 
      levels = c("Underweight", "Normal", "Overweight", "Obesity"), 
      ordered = TRUE)) %>%
  mutate(milk_type = factor(
      milk_type, 
      levels = c("0", "1", "2", "3", '4', '8', '9'), 
      ordered = TRUE)) %>%
  mutate(milk_consumption = factor(
      milk_consumption, 
      levels = c("0", "1", "2", "3", '9'), 
      ordered = TRUE))

final_data <- final_data %>%
  mutate(poverty_category = as.numeric(poverty_category)) %>%
  mutate(alcohol_frequency = as.numeric(alcohol_frequency)) %>%
  mutate(diabetes_status = as.numeric(diabetes_status)) %>%
  mutate(household_smoking_status = as.numeric(household_smoking_status)) %>%
  mutate(fast_food_consumption = as.numeric(fast_food_consumption))
```

## Realtionship between variable of interest

```{r, fig.width=10, fig.height=10}
# Custom labels for BMI categories
custom_labels <- c(
  "Underweight" = "Under\nWeight",
  "Normal" = "Normal",
  "Overweight" = "Over\nWeight",
  "Obesity" = "Obesity"
)

# Custom labels for each facet
facet_labels <- c(
  "poverty_category" = "Poverty Category",
  "alcohol_frequency" = "Alcohol Frequency",
  "diabetes_status" = "Diabetes Status",
  "household_smoking_status" = "Household Smoking Status",
  "fast_food_consumption" = "Fast Food Consumption",
  "sleep_hours" = "Hours of Sleep",
  "milk_type" = "Milk Type",
  "milk_consumption" = "Milk Consumption"
)

plot <- final_data %>%
  mutate(
    milk_type = as.numeric(as.character(milk_type)),
    milk_consumption = as.numeric(as.character(milk_consumption))
  ) %>%
  pivot_longer(
    cols = c(poverty_category, alcohol_frequency, diabetes_status, household_smoking_status, fast_food_consumption, sleep_hours, milk_type, milk_consumption), 
    names_to = "variable",
    values_to = "value" # reshape data
  ) %>%
  ggplot(aes(x = bmi_category, y = value, fill = bmi_category)) +
  geom_boxplot(alpha = 0.7, outlier.color = "red")+ 
  scale_x_discrete(labels = custom_labels) +
  facet_wrap(~ variable, scales = "free_y", labeller = labeller(variable = facet_labels), ncol = 4) + # create facet for each variable
  labs(
    title = "Relationship Between Variables of Interest and BMI Categories",
    x = "BMI Category",
    y = "Variable of Interest Value"
  ) +
  theme_minimal() +
  theme( # customize font size and style
    legend.position = "none",
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 10, angle = 45, hjust = 1),
    strip.text = element_text(size = 12), # larger facet title
    axis.title = element_text(size = 12, face = "bold")
        ) 
# save plot
ggsave("relation_btw_variable.png", plot=plot, width = 10, height = 5)
# display plot
plot
```


## Correlation

-   ordinal variable
-   non-linear relationship -\> use spearman correlation

```{r}
# Calculate the correlation matrix for each variable pairs
cor_matrix <- final_data %>%
  dplyr::select(poverty_category, alcohol_frequency, diabetes_status, household_smoking_status, fast_food_consumption, sleep_hours, milk_type, milk_consumption) %>%
  mutate(
    milk_type = as.numeric(as.character(milk_type)),
    milk_consumption = as.numeric(as.character(milk_consumption))
  ) %>% 
  cor(method = "spearman")

# Visualize the correlation matrix

cor_plot <- ggcorrplot(cor_matrix, method = "circle", title = "Correlation Between Predictors")
ggsave("correlation_matrix.png", plot=cor_plot) # save plot
cor_plot
```


## Scaling

```{r}
# Plot the distribution of sleep hours
sleep_plot <- ggplot(final_data, aes(x = sleep_hours)) +
  geom_histogram(binwidth = 0.5, fill = "skyblue", color = "black", alpha = 0.7) +
  geom_density(aes(y = after_stat(count)), color = "darkblue", size = 1.2) +
  labs(
    title = "Distribution of Sleep Hours",
    x = "Sleep Hours",
    y = "Frequency"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 12, face = "bold")
  )

ggsave("sleep_distribution.png", plot=sleep_plot) # save plot
sleep_plot
```

```{r}
# Scaling Continuous Variables
final_data <- final_data %>%
  mutate_at(vars(sleep_hours), 
            scale)
summary(final_data)
```

# Model Building

```{r, warning=FALSE}
# Ensure target variable is a factor
final_data$bmi_category <- as.factor(final_data$bmi_category)

# Data Preparation and Scaling
scale_columns <- c("sleep_hours", "fast_food_consumption", "poverty_category", 
                   "alcohol_frequency", "diabetes_status", "household_smoking_status")

final_data[scale_columns] <- scale(final_data[scale_columns])

# Train-Test Split
set.seed(123)
train_index <- createDataPartition(final_data$bmi_category, p = 0.8, list = FALSE)
train_data <- final_data[train_index, ]
test_data <- final_data[-train_index, ]

# Prepare Data for glmnet
x <- model.matrix(bmi_category ~ ., data = final_data)[, -1]
y <- as.factor(final_data$bmi_category)
x_train <- x[train_index, ]
y_train <- y[train_index]
x_test <- x[-train_index, ]
y_test <- y[-train_index]

# Check Split
cat("Training Rows:", nrow(train_data), "\nTesting Rows:", nrow(test_data), "\n")

# --------------------------------------------------------------------
# Hyperparameter Tuning for LASSO/Elastic Net
# --------------------------------------------------------------------
set.seed(123)
# Alpha grid search: LASSO, Ridge, Elastic Net
alphas <- seq(0, 1, by = 0.1)
cv_results <- list()

# Loop over alpha values to find the best alpha
for (a in alphas) {
  lasso_model <- cv.glmnet(x_train, y_train, family = "multinomial", alpha = a, type.measure = "class")
  cv_results[[paste0("alpha_", a)]] <- list(
    lambda_min = lasso_model$lambda.min,
    accuracy = min(lasso_model$cvm)
  )
}
best_alpha <- alphas[which.min(sapply(cv_results, function(x) x$accuracy))]
cat("Best Alpha:", best_alpha, "\n")

# Train Model with Best Alpha Found
set.seed(123)
final_lasso_model <- cv.glmnet(x_train, y_train, family = "multinomial", alpha = best_alpha, type.measure = "class")
optimal_lambda <- final_lasso_model$lambda.min
cat("Optimal Lambda:", optimal_lambda, "\n")

# Predictions and Evaluation
lasso_predictions <- predict(final_lasso_model, newx = x_test, s = optimal_lambda, type = "class")
lasso_confusion <- confusionMatrix(as.factor(lasso_predictions), as.factor(y_test))
lasso_accuracy <- lasso_confusion$overall["Accuracy"]

# Plot Regularization Paths
plot(final_lasso_model$glmnet.fit, xvar = "lambda", label = TRUE)
abline(v = log(optimal_lambda), col = "red", lty = 2) # Line for optimal lambda
legend("topright", legend = "Optimal Lambda", col = "red", lty = 2, cex = 0.8)
title("Coefficient Path (LASSO/Elastic Net)")

# Plot Cross-Validation Curve
plot(final_lasso_model, main = "Cross-Validation Curve for LASSO")
abline(v = log(optimal_lambda), col = "red", lty = 2) # Line for optimal lambda
legend("topright", legend = "Optimal Lambda", col = "red", lty = 2, cex = 0.8)

# Plot LASSO Confusion Matrix
lasso_conf_matrix <- table(Predicted = lasso_predictions, Actual = y_test)
lasso_conf_matrix_plot <- as.data.frame(as.table(lasso_conf_matrix))
ggplot(lasso_conf_matrix_plot, aes(x = Predicted, y = Actual, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq), color = "black", size = 5) +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(title = "Confusion Matrix Heatmap (LASSO)", x = "Predicted Category", y = "Actual Category") +
  theme_minimal()
```

```{r}
# Find 
str(final_data[scale_columns])
```

```{r, warning=FALSE}
# Standardize Predictors
scale_columns <- c("sleep_hours", "fast_food_consumption", "poverty_category", 
                   "alcohol_frequency", "diabetes_status", "household_smoking_status")

final_data[scale_columns] <- scale(final_data[scale_columns])

# Extract Predictors and Response Variable
predictors <- final_data[, scale_columns]
response <- as.factor(final_data$bmi_category)

# Perform PCA
set.seed(123)
pca_result <- prcomp(predictors, center = TRUE, scale. = TRUE)
summary_pca <- summary(pca_result)
print(summary_pca)

# Scree Plot to Decide Number of PCs
scree_data <- data.frame(PC = 1:length(summary_pca$importance[2,]),
                         Variance = summary_pca$importance[2,])
ggplot(scree_data, aes(x = PC, y = Variance)) +
  geom_line() + geom_point() +
  labs(title = "Scree Plot to find Optimal Number of PC", x = "Principal Component", y = "Proportion of Variance Explained") +
  theme_minimal()

# Choose Top k PCs explaining 90%+ variance)
num_pcs <- which(cumsum(summary_pca$importance[2,]) >= 0.9)[1]
cat("Number of PCs explaining 90% variance:", num_pcs, "\n")

# Prepare Data with Selected PCs
pc_data <- as.data.frame(pca_result$x[, 1:num_pcs])
pc_data$bmi_category <- response

# Train-Test Split
set.seed(123)
train_index <- createDataPartition(pc_data$bmi_category, p = 0.8, list = FALSE)
train_data <- pc_data[train_index, ]
test_data <- pc_data[-train_index, ]

# Prepare Data for Multinomial Logistic Regression
x_train <- as.matrix(train_data[, -ncol(train_data)])
y_train <- train_data$bmi_category
x_test <- as.matrix(test_data[, -ncol(test_data)])
y_test <- test_data$bmi_category

# Train LASSO/Elastic Net on PCs
set.seed(123)
lasso_pca_model <- cv.glmnet(x_train, y_train, family = "multinomial", alpha = 1, type.measure = "class")

# Optimal Lambda
optimal_lambda <- lasso_pca_model$lambda.min
cat("Optimal Lambda (PCA + LASSO):", optimal_lambda, "\n")

# Predictions and Evaluation
lasso_pca_predictions <- predict(lasso_pca_model, newx = x_test, s = optimal_lambda, type = "class")
lasso_pca_confusion <- confusionMatrix(as.factor(lasso_pca_predictions), as.factor(y_test))
lasso_pca_accuracy <- lasso_pca_confusion$overall["Accuracy"]

# Plot Confusion Matrix
conf_matrix <- table(Predicted = lasso_pca_predictions, Actual = y_test)
conf_matrix_plot <- as.data.frame(as.table(conf_matrix))

ggplot(conf_matrix_plot, aes(x = Predicted, y = Actual, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq), color = "black", size = 5) +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(title = "Confusion Matrix Heatmap (PCA + LASSO)", x = "Predicted Category", y = "Actual Category") +
  theme_minimal()
```

```{r}
# --------------------------------------------------------------------
# Model Comparison Summary
# --------------------------------------------------------------------
comparison <- data.frame(
  Model = c("Original LASSO Logistic Regression", "Alternative (PCA + LASSO) Logistic Regression"),
  Accuracy = c(round(lasso_accuracy, 3), round(lasso_pca_accuracy, 3))
)
comparison
```
# Follow-up Analysis
Please refer to the model evaluation matrix in the previous section for the accuracy of the LASSO model and the alternative model on the held-out test data.

# Permutation

```{r, warning=FALSE}
# Number of permutations
n_permutations <- 1000

# Store permuted accuracies
permuted_accuracies <- numeric(n_permutations)

# Original Model Accuracy
original_accuracy <- lasso_accuracy  # Use the accuracy from your original model

# Permutation Loop
set.seed(123)
for (i in 1:n_permutations) {
  # Permute the response variable
  y_train_permuted <- sample(y_train)
  
  # Fit the LASSO model on permuted data
  permuted_model <- cv.glmnet(x_train, y_train_permuted, family = "multinomial", 
                              alpha = best_alpha, type.measure = "class")
  
  # Predict on test set using optimal lambda
  permuted_predictions <- predict(permuted_model, newx = x_test, 
                                  s = permuted_model$lambda.min, type = "class")
  
  # Calculate accuracy on test set
  permuted_confusion <- confusionMatrix(as.factor(permuted_predictions), as.factor(y_test))
  permuted_accuracies[i] <- permuted_confusion$overall["Accuracy"]
}
```

```{r}
# Calculate Permutation-Based p-value
p_value <- mean(permuted_accuracies >= original_accuracy)

# Print Results
cat("Original Model Accuracy:", original_accuracy, "\n")
cat("Permutation-based p-value:", p_value, "\n")

# Plot Permutation Distribution
permuted_data <- data.frame(Accuracy = permuted_accuracies)

# Plot using ggplot
plot <- ggplot(permuted_data, aes(x = Accuracy)) +
  geom_histogram(bins = 40, fill = "lightblue", color = "black") +
  labs(
    title = "Permutation Test for LASSO Model",
    x = "Accuracy",
    y = "Frequency"
  ) +
  theme_minimal()+
  theme(
    legend.position = "none",
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 10, hjust = 1),
    axis.title = element_text(size = 12, face = "bold")
        ) 
 ggsave("permutation_test.png", plot=plot, width = 10, height = 5)
 plot
```

